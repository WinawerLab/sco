% compare_with_Kay2013.m
% 
% this matlab script is the complement of compare_with_Kay2013.py
% and will be run after it to produce results to compare to the
% outputs of the python code.
%
% Assumes you used the default gabor filter options in the python
% code (8 orientations, etc) -- unclear about cycles per image.
% 
% currently, this is the naive way of implementing this, we don't
% take advantage of parallelizing in any way, since this is only
% for small tests.
% 
% By William F. Broderick

function compareWithKay2013(knkutilsPath, stimuliPath, stimuliIdx, voxelIdx, modelPath, stimuliNamesPath, savePath)
% arguments:
% 
% knkutilsPath: string, path to your knkutils folder, which we'll
% add to the matlab path
% 
% stimuliPath: string, path to stimuli.mat which we'll grab the
% input images from
% 
% stimuliIdx: vector, subset of images to use for these models, or
% string, path to a .txt file that contains said vector. This should
% be matlab indices, so 1-indexed and whatever you passed to the
% python function +1.
% 
% voxelIdx: vector, subset of voxels to generate predictions for
% (there's no reason to run this function for every voxel), or string,
% path to a .txt file that contains said vector. This should
% correspond to the values in your model dataframe / table and so is
% probably 0-indexed. We will use modelTable.voxel==voxelIdx(i) to
% find the appropriate values
% 
% modelPath: string, path to the python dataframe / matlab table
% containing all the model parameters
% 
% stimuliNamesPath: string, path to the stimuliNames .mat. This will
% be a struct, with only one field: image_names, which will contain a
% vector with names of the images (to grab from modelTable). Will
% probably not be the same size as stimuliIdx because some of our
% stimuli consist of multiple frames and they have the same index
% while having different names. (eg, stimuliIdx=[70],
% stimuliNames=['0069-00', '0069-01', ..., '0069-08'], because
% stimuli(70) has 9 frames). Note that the names are most likely
% generated by python, so they will probably be 0-indexed instead of
% 1-indexed.
% 
% savePath: string, path to save the updated python dataframe /
% matlab table at (should probably be a csv)
    modelTable = readtable(modelPath);
    addpath(genpath(knkutilsPath));
    load(stimuliPath, 'images');
    if ischar(stimuliIdx)
        stimuliIdx = load(stimuliIdx);
    end
    stimuli = images(stimuliIdx);
    clear images;
    
    stimuliNames = load(stimuliNamesPath);
    stimuliNames = stimuliNames.image_names;
    stimuliNames = cellstr(stimuliNames);
    
    for imgIdx=1:length(stimuliNames)
        eval(sprintf('modelTable.MATLAB_predicted_responses_image_%s=nan(height(modelTable),1);',stimuliNames{imgIdx}));
    end
    
    [stimuli, normAlreadyDoneFlag] = preprocessStimuli(stimuli, modelTable);
    
    % we want to look at the contrast images.
    save('contrast_images.mat','stimuli');
    
    if ischar(voxelIdx)
        voxelIdx = load(voxelIdx);
    end
    for vox=voxelIdx
        if ~normAlreadyDoneFlag
            stimuliTmp = divisiveNormalization(stimuli, modelTable, modelTable.voxel==voxelIdx);
        else
            stimuliTmp = stimuli;
        end
        modelTable = generateVoxelPredictions(stimuliTmp, modelTable, vox, stimuliNames);
    end
    writetable(modelTable, savePath);
end

function [stimuli, normAlreadyDoneFlag] = preprocessStimuli(stimuli, modelTable)
% Preprocess the stimuli for use by all the voxels: resize, make sure
% that all values lay between 0 and 254, then rescale to being between
% 0 and 1 and then mean-center (so they lie between -.5 and .5). Then
% pad stimuli with zeros to reduce edge effects. We then move onto the
% more specialized preprocessing: applying the gabor filters (note
% that this assumes you used the defaults in the python code!) and, if
% we can, divisive normalization (we apply divisive normalization here
% if all voxels have the same divisive normalization parameters)

    stimuli = cat(3,stimuli{:});
    % resize the stimuli to 150 x 150 to reduce computational time.
    % use single-format to save memory.
    temp = zeros(150,150,size(stimuli,3),'single');
    for p=1:size(stimuli,3)
        temp(:,:,p) = imresize(single(stimuli(:,:,p)),[150 150],'cubic');
    end        
    stimuli = temp;
    clear temp;

    % ensure that all values are between 0 and 254.
    % rescale values to the range [0,1].
    % subtract off the background luminance (0.5).
    % after these steps, all pixel values will be in the 
    % range [-.5,.5] with the background corresponding to 0.
    stimuli(stimuli < 0) = 0;
    stimuli(stimuli > 254) = 254;
    stimuli = stimuli/254 - 0.5;

    % pad the stimuli with zeros (to reduce edge effects).
    % the new resolution is 180 x 180 (15-pixel padding on each side).
    stimuli = placematrix(zeros(180,180,size(stimuli,3),'single'),stimuli);
   
    % apply Gabor filters to the stimuli.  filters occur at different positions, 
    % orientations, and phases.  there are several parameters that govern the
    % design of the filters:
    %   the number of cycles per image is 37.5*(180/150)
    %   the spatial frequency bandwidth of the filters is 1 octave
    %   the separation of adjacent filters is 1 std dev of the Gaussian envelopes
    %     (this results in a 90 x 90 grid of positions)
    %   filters occur at 8 orientations
    %   filters occur at 2 phases (between 0 and pi)
    %   the Gaussian envelopes are thresholded at .01
    %   filters are scaled to have an equivalent Michelson contrast of 1
    %   the dot-product between each filter and each stimulus is computed
    % after this step, stimulus is images x phases*orientations*positions.
    stimuli = applymultiscalegaborfilters(reshape(stimuli,180*180,[])', ...
                                          37.5*(180/150),-1,1,8,2,.01,2,0);
    
    % compute the square root of the sum of the squares of the outputs of 
    % quadrature-phase filter pairs (this is the standard complex-cell energy model).
    % after this step, stimulus is images x orientations*positions.
    stimuli = sqrt(blob(stimuli.^2,2,2));

    if range(modelTable.Kay2013_normalization_r)==0 && range(modelTable.Kay2013_normalization_s)==0
        % if they all have the same r and s, we can do this here.
        
        normAlreadyDoneFlag = true;
        
        % We call divisive normalization, using parameter values
        % from the first voxel (since they're all the same)
        stimuli = divisiveNormalization(stimuli, modelTable, 1);
    else
        normAlreadyDoneFlag = false;
    end
    
end

function stimuli =  divisiveNormalization(stimuli, modelTable, modelIdx)
% compute the population term in the divisive-normalization equation.  
% this term is simply the average across the complex-cell outputs 
% at each position (averaging across orientation).
% 
% modelIdx can either be a single integer or a boolean array, in which
% case we take the value from the corresponding row. The boolean
% array has only been tested with one 1s (and the rest 0s) and
% allows us to pass modelTable.voxel==voxelIdx as an index.
    stimuliPOP = blob(stimuli,2,8)/8;

    % repeat the population term for each of the orientations
    stimuliPOP = upsamplematrix(stimuliPOP,8,2,[],'nearest');
    
    % We only do this if all voxels have the same r and s
    r = modelTable.Kay2013_normalization_r(modelIdx);
    s = modelTable.Kay2013_normalization_s(modelIdx);
    
    % apply divisive normalization to the complex-cell outputs.  there are two parameters
    % that influence this operation: an exponent term (r) and a semi-saturation term (s).  
    % the parameter values specified here were determined through a separate fitting 
    % procedure (see paper for details).  for the purposes of this script, we will 
    % simply hard-code the parameter values here and not worry about attempting to fit 
    % the parameters.
    stimuli = stimuli.^r ./ (s.^r + stimuliPOP.^r);
    clear stimuliPOP;

    % sum across orientation.  after this step, stimuli is images x positions.
    stimuli = blob(stimuli,2,8);

end

function modelTable = generateVoxelPredictions(stimuli, modelTable, voxelIdx, stimuliNames)
% The parameters are [R C S G N C] where
%   R is the row index of the center of the 2D Gaussian (pRF_pixel_centers_image_###_dim0)
%   C is the column index of the center of the 2D Gaussian (pRF_pixel_centers_image_###_dim1)
%   S is the standard deviation of the 2D Gaussian (pRF_pixel_sizes)
%   G is a gain parameter (Kay2013_response_gain)
%   N is the exponent of the power-law nonlinearity (Kay2013_output_nonlinearity)
%   C is a parameter that controls the strength of second-order contrast (Kay2013_SOC_constant)

    % resolution of the pre-processed stimuli; this is taken from
    % Kendrick's socmodel_example, because after the gabor filters
    % are applied, your stimuli are all 90x90
    res = 90;
    % issue a dummy call to makegaussian2d.m to pre-compute xx and yy.
    % these variables are re-used to achieve faster computation.
    [~,xx,yy] = makegaussian2d(res,2,2,2,2);
    
    socfun = @(dd,wts,c) bsxfun(@minus,dd,c*(dd*wts)).^2 * wts;
    gaufun = @(pp) vflatten(makegaussian2d(res,pp(1),pp(2),pp(3),pp(3),xx,yy,0,0)/(2*pi*pp(3)^2));
    modelfun = @(pp,dd) pp(4)*(socfun(dd,gaufun(pp),restrictrange(pp(6),0,1)).^pp(5));
    
    for idx=1:length(stimuliNames)
        params = [floor(eval(sprintf('modelTable.pRF_pixel_centers_image_%s_dim0(modelTable.voxel==%d)', stimuliNames{idx}, voxelIdx))),
                  floor(eval(sprintf('modelTable.pRF_pixel_centers_image_%s_dim1(modelTable.voxel==%d)', stimuliNames{idx}, voxelIdx))),
                  eval(sprintf('modelTable.pRF_pixel_sizes_image_%s(modelTable.voxel==%d)', stimuliNames{idx}, voxelIdx)),
                  modelTable.Kay2013_response_gain(modelTable.voxel==voxelIdx),
                  modelTable.Kay2013_output_nonlinearity(modelTable.voxel==voxelIdx),
                  modelTable.Kay2013_SOC_constant(modelTable.voxel==voxelIdx)];
        modelfit = modelfun(params, stimuli(idx,:));
        eval(sprintf('modelTable.MATLAB_predicted_responses_image_%s(modelTable.voxel==%d) = %d;', stimuliNames{idx},voxelIdx,modelfit));
    end

end