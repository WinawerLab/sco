% compare_with_Kay2013.m
% 
% this matlab script is the complement of compare_with_Kay2013.py
% and will be run after it to produce results to compare to the
% outputs of the python code.
%
% Assumes you used the default gabor filter options in the python
% code (8 orientations, etc) -- unclear about cycles per image.
% 
% currently, this is the naive way of implementing this, we don't
% take advantage of parallelizing in any way, since this is only
% for small tests.
% 
% By William F. Broderick

function compareWithKay2013(knkutilsPath, stimuliPath, stimuliIdx, voxelIdx, modelPath, stimuliNamesPath, savePath)
% arguments:
% 
% knkutilsPath: string, path to your knkutils folder, which we'll
% add to the matlab path
% 
% stimuliPath: string, path to stimuli.mat which we'll grab the
% input images from
% 
% stimuliIdx: vector, subset of images to use for these models, or
% string, path to a .txt file that contains said vector. This should
% be matlab indices, so 1-indexed and whatever you passed to the
% python function +1.
% 
% voxelIdx: vector, subset of voxels to generate predictions for
% (there's no reason to run this function for every voxel), or string,
% path to a .txt file that contains said vector. This should
% correspond to the values in your model dataframe / table and so is
% probably 0-indexed. We will use modelTable.voxel==voxelIdx(i) to
% find the appropriate values
% 
% modelPath: string, path to the python dataframe / matlab table
% containing all the model parameters
% 
% stimuliNamesPath: string, path to the stimuliNames .mat. This will
% be a struct, with only one field: image_names, which will contain a
% vector with names of the images (to grab from modelTable). Will
% probably not be the same size as stimuliIdx because some of our
% stimuli consist of multiple frames and they have the same index
% while having different names. (eg, stimuliIdx=[70],
% stimuliNames=['0069-00', '0069-01', ..., '0069-08'], because
% stimuli(70) has 9 frames). Note that the names are most likely
% generated by python, so they will probably be 0-indexed instead of
% 1-indexed.
% 
% savePath: string, path to save the updated python dataframe /
% matlab table at (should probably be a csv)
    modelTable = readtable(modelPath);
    addpath(genpath(knkutilsPath));
    load(stimuliPath, 'images');
    if ischar(stimuliIdx)
        stimuliIdx = load(stimuliIdx);
    end
    imgSize = size(images);
    % then we need to unfold the stimulus_images; each stimulus is 3
    % dimensional (several two dimensional images), so if it's only
    % two dimensional and the first dimension is 1, this is collapsed
    % across that dimension (happens when not all stimuli are the same
    % size). It's a bunch of cells, so the second line is necessary to
    % get it into the 3d matrix we want.
    if length(imgSize) == 2 && imgSize(1) == 1
        stimuli = images(stimuliIdx);
    else
        % then we need to grab the corresponding stimuli
        stimuli = images(stimuliIdx, :, :, :);
        % we wrangle this into the same shape, a 1d cell array, as
        % above, so the cat call works.
        tmp = cell(1,size(stimuli,1));
        for ii=1:size(stimuli,1)
            tmp{ii} = squeeze(images(ii,:,:,:));
        end
        stimuli = tmp;
    end
    stimuli = cat(3,stimuli{:});
    clear images tmp;
    
    stimuliNames = load(stimuliNamesPath);
    stimuliNames = stimuliNames.image_names;
    stimuliNames = cellstr(stimuliNames);
    
    for imgIdx=1:length(stimuliNames)
        eval(sprintf('modelTable.MATLAB_predicted_responses_image_%s=nan(height(modelTable),1);',stimuliNames{imgIdx}));
    end
    
    [stimuli, normAlreadyDoneFlag] = preprocessStimuli(stimuli, modelTable);
    
    % we want to look at the contrast images.
    save('contrast_images.mat','stimuli');
    
    if ischar(voxelIdx)
        voxelIdx = load(voxelIdx);
    end
    for vox=voxelIdx
        if ~normAlreadyDoneFlag
            stimuliTmp = divisiveNormalization(stimuli, modelTable, modelTable.voxel==voxelIdx);
        else
            stimuliTmp = stimuli;
        end
        modelTable = generateVoxelPredictions(stimuliTmp, modelTable, vox, stimuliNames);
    end
    writetable(modelTable, savePath);
end

function [stimuli, normAlreadyDoneFlag] = preprocessStimuli(stimuli, modelTable)
% Preprocess the stimuli for use by all the voxels: resize, make sure
% that all values lay between 0 and 254, then rescale to being between
% 0 and 1 and then mean-center (so they lie between -.5 and .5). Then
% pad stimuli with zeros to reduce edge effects. We then move onto the
% more specialized preprocessing: applying the gabor filters (note
% that this assumes you used the defaults in the python code!) and, if
% we can, divisive normalization (we apply divisive normalization here
% if all voxels have the same divisive normalization parameters)

    % resize the stimuli to 150 x 150 to reduce computational time.
    % use single-format to save memory.
    temp = zeros(150,150,size(stimuli,3),'single');
    for p=1:size(stimuli,3)
        temp(:,:,p) = imresize(single(stimuli(:,:,p)),[150 150],'cubic');
    end        
    stimuli = temp;
    clear temp;

    % ensure that all values are between 0 and 254.
    % rescale values to the range [0,1].
    % subtract off the background luminance (0.5).
    % after these steps, all pixel values will be in the 
    % range [-.5,.5] with the background corresponding to 0.
    stimuli(stimuli < 0) = 0;
    stimuli(stimuli > 254) = 254;
    stimuli = stimuli/254 - 0.5;

    % pad the stimuli with zeros (to reduce edge effects).
    % the new resolution is 180 x 180 (15-pixel padding on each side).
    stimuli = placematrix(zeros(180,180,size(stimuli,3),'single'),stimuli);
   
    % The following shows Kendrick's original notes, with Noah's
    % additional explanations. 
    
    % apply Gabor filters to the stimuli.  filters occur at different positions, 
    % orientations, and phases.  there are several parameters that govern the
    % design of the filters:
    % 
    %   the number of cycles per image is 37.5*(180/150). This is 45
    %   cycles per image; since there are 180 pixels, we get .25
    %   cycles/pixel
    % 
    %   the spatial frequency bandwidth of the filters is 1
    %   octave. This should give us the relationship between frequency
    %   and standard deviation. For the bandwidth b, freqnecy f,
    %   standard deviation s, and constant q = sqrt(ln(2)/2): b =
    %   log2( (s/f * pi + q) / (s/f * pi - q)), giving us that
    %   here, sigma is approximately 2.25 pixels
    % 
    %   the separation of adjacent filters is 1 std dev of the
    %   Gaussian envelopes (this results in a 90 x 90 grid of
    %   positions). The fact that 180x180 turns into 90x90 tells me
    %   that 1 std of the Gaussian envelope is 2 pixels, which
    %   approximately matches above.
    % 
    %   filters occur at 8 orientations
    % 
    %   filters occur at 2 phases (between 0 and pi) (this is the
    %   real and imaginary parts of the Gabor)
    % 
    %   the Gaussian envelopes are thresholded at .01. This means
    %   that the Gaussian envelope was thresholded at 3 standard
    %   devaitions, so with a Gaussian envelope of 2.25 pixels, the
    %   filter would be 13.5 x 13.5 pixels^2. Or for a 2 pixel
    %   envelope, 12 x 12 pixels^2
    % 
    %   filters are scaled to have an equivalent Michelson contrast of
    %   1 This just means that the minimum value of the filter image
    %   is 0, so doesn't make any sense to me. Michelson contrast
    %   is (max(image) - min(image)) / (max(image) +
    %   min(image)). Shouldn't the minimum value of the filter
    %   image be negative? Typically one scales filters to have a
    %   power of 1 and a mean of 0.
    % 
    %   the dot-product between each filter and each stimulus is
    %   computed.
    % 
    % after this step, stimulus is images x phases*orientations*positions.
    stimuli = applymultiscalegaborfilters(reshape(stimuli,180*180,[])', ...
                                          37.5*(180/150),-1,1,8,2,.01,2,0);
    
    % compute the square root of the sum of the squares of the outputs of 
    % quadrature-phase filter pairs (this is the standard complex-cell energy model).
    % after this step, stimulus is images x orientations*positions.
    stimuli = sqrt(blob(stimuli.^2,2,2));

    if range(modelTable.Kay2013_normalization_r)==0 && range(modelTable.Kay2013_normalization_s)==0
        % if they all have the same r and s, we can do this here.
        
        normAlreadyDoneFlag = true;
        
        % We call divisive normalization, using parameter values
        % from the first voxel (since they're all the same)
        stimuli = divisiveNormalization(stimuli, modelTable, 1);
    else
        normAlreadyDoneFlag = false;
    end
    
end

function stimuli =  divisiveNormalization(stimuli, modelTable, modelIdx)
% compute the population term in the divisive-normalization equation.  
% this term is simply the average across the complex-cell outputs 
% at each position (averaging across orientation).
% 
% modelIdx can either be a single integer or a boolean array, in which
% case we take the value from the corresponding row. The boolean
% array has only been tested with one 1s (and the rest 0s) and
% allows us to pass modelTable.voxel==voxelIdx as an index.
    stimuliPOP = blob(stimuli,2,8)/8;

    % repeat the population term for each of the orientations
    stimuliPOP = upsamplematrix(stimuliPOP,8,2,[],'nearest');
    
    % We only do this if all voxels have the same r and s
    r = modelTable.Kay2013_normalization_r(modelIdx);
    s = modelTable.Kay2013_normalization_s(modelIdx);
    
    % apply divisive normalization to the complex-cell outputs.  there are two parameters
    % that influence this operation: an exponent term (r) and a semi-saturation term (s).  
    % the parameter values specified here were determined through a separate fitting 
    % procedure (see paper for details).  for the purposes of this script, we will 
    % simply hard-code the parameter values here and not worry about attempting to fit 
    % the parameters.
    stimuli = stimuli.^r ./ (s.^r + stimuliPOP.^r);
    clear stimuliPOP;

    % sum across orientation.  after this step, stimuli is images x positions.
    stimuli = blob(stimuli,2,8);

end

function modelTable = generateVoxelPredictions(stimuli, modelTable, voxelIdx, stimuliNames)
% The parameters are [R C S G N C] where
%   R is the row index of the center of the 2D Gaussian (pRF_pixel_centers_row_image_####/2)
%   C is the column index of the center of the 2D Gaussian (pRF_pixel_centers_col_image_####/2)
%   S is the standard deviation of the 2D Gaussian (pRF_pixel_sizes_image_####/2)
%   G is a gain parameter (Kay2013_response_gain)
%   N is the exponent of the power-law nonlinearity (Kay2013_output_nonlinearity)
%   C is a parameter that controls the strength of second-order contrast (Kay2013_SOC_constant)
    
% the image-related parameters (R, C, and S) are all divided by two
% because the MATLAB code operates on images that are 90x90, whereas
% the python code operates on images that are 180x180 (both are
% 180x180 at first, but the MATLAB code downsamples the images when
% they go through the applymultiscalegaborfilters call). Thus the
% division by two is necessary in order to make sure the pRFs
% correspond to the same part of the image.

    % resolution of the pre-processed stimuli; this is taken from
    % Kendrick's socmodel_example, because after the gabor filters
    % are applied, your stimuli are all 90x90
    res = 90;
    % issue a dummy call to makegaussian2d.m to pre-compute xx and yy.
    % these variables are re-used to achieve faster computation.
    [~,xx,yy] = makegaussian2d(res,2,2,2,2);
    
    socfun = @(dd,wts,c) bsxfun(@minus,dd,c*(dd*wts)).^2 * wts;
    gaufun = @(pp) vflatten(makegaussian2d(res,pp(1),pp(2),pp(3),pp(3),xx,yy,0,0)/(2*pi*pp(3)^2));
    modelfun = @(pp,dd) pp(4)*(socfun(dd,gaufun(pp),restrictrange(pp(6),0,1)).^pp(5));
    
    for idx=1:length(stimuliNames)
        params = [floor(eval(sprintf('modelTable.pRF_pixel_centers_row_image_%s(modelTable.voxel==%d)/2', stimuliNames{idx}, voxelIdx))),
                  floor(eval(sprintf('modelTable.pRF_pixel_centers_col_image_%s(modelTable.voxel==%d)/2', stimuliNames{idx}, voxelIdx))),
                  eval(sprintf('modelTable.pRF_pixel_sizes_image_%s(modelTable.voxel==%d)/2', stimuliNames{idx}, voxelIdx)),
                  modelTable.Kay2013_response_gain(modelTable.voxel==voxelIdx),
                  modelTable.Kay2013_output_nonlinearity(modelTable.voxel==voxelIdx),
                  modelTable.Kay2013_SOC_constant(modelTable.voxel==voxelIdx)];
        modelfit = modelfun(params, stimuli(idx,:));
        eval(sprintf('modelTable.MATLAB_predicted_responses_image_%s(modelTable.voxel==%d) = %d;', stimuliNames{idx},voxelIdx,modelfit));
    end

end